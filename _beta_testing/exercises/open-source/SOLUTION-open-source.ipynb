{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "removed-truth",
   "metadata": {},
   "source": [
    "# **DSFM Exercise**: Open-source Models - style transfer (SOLUTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-pointer",
   "metadata": {},
   "source": [
    "Creator: [Data Science for Managers - EPFL Program](https://www.dsfm.ch)  \n",
    "Source:  [https://github.com/dsfm-org/code-bank.git](https://github.com/dsfm-org/code-bank.git)  \n",
    "License: [MIT License](https://opensource.org/licenses/MIT). See open source [license](LICENSE) in the Code Bank repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-karaoke",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-norfolk",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-taylor",
   "metadata": {},
   "source": [
    "In this exercise, we leverage an open-source model to show the power of re-using existing work from the data science community. We will convert the style of an image, based on a pre-trained open-source model.\n",
    "\n",
    "This *neural style transfer* takes a *content image* and a *style reference image* (e.g. by Picasso, Kandinsky, Van Gogh). The goal is to \"paint\" the content image in the style of the reference image, using neural networks.\n",
    "\n",
    "Original paper: *A Neural Algorithm of Artistic Style* by [Gatys et al. (2015)](https://arxiv.org/abs/1508.06576)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-timothy",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-radar",
   "metadata": {},
   "source": [
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import time\n",
    "import functools\n",
    "\n",
    "# Define plotting format\n",
    "mpl.rcParams['figure.figsize'] = (12, 12)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "# Load compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return PIL.Image.fromarray(tensor)\n",
    "\n",
    "def load_img(path_to_img):\n",
    "    max_dim = 512\n",
    "    img = tf.io.read_file(path_to_img)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    long_dim = max(shape)\n",
    "    scale = max_dim / long_dim\n",
    "\n",
    "    new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "    img = tf.image.resize(img, new_shape)\n",
    "    img = img[tf.newaxis, :]\n",
    "    return img\n",
    "\n",
    "def imshow(image, title=None):\n",
    "    if len(image.shape) > 3:\n",
    "        image = tf.squeeze(image, axis=0)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-poetry",
   "metadata": {},
   "source": [
    "# **MAIN EXERCISE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-henry",
   "metadata": {},
   "source": [
    "## Part 1: Upload image\n",
    "\n",
    "Upload an image to the directory of this notebook. You can (1) upload an image from your computer or (2) copy an image from the web. We encourage the former â€“ it's more fun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-mileage",
   "metadata": {},
   "source": [
    "**Q 1:** Upload image in `.jpg` format and replace the existing `myImage.jpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-backup",
   "metadata": {},
   "source": [
    "**Q 2:** Rename image to `myImage.jpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-retro",
   "metadata": {},
   "source": [
    "## Part 2: Choose style image\n",
    "\n",
    "Now comes the creative part. Choose one of the available style reference images below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-reduction",
   "metadata": {},
   "source": [
    "**Q 1:** Define the path to the style image in the `/styles` directory. \n",
    "\n",
    "Hint: Create a variable called `content_path` to reference the style image you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_path = 'styles/kandinsky.jpg'\n",
    "# style_path = 'styles/vanGogh.jpg'\n",
    "# style_path = 'styles/monet.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-warrant",
   "metadata": {},
   "source": [
    "**Q 2:** Show the style image.\n",
    "\n",
    "Hint: Use the `load_img()` and `imshow()` helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image = load_img(style_path)\n",
    "imshow(style_image, 'Style Image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-vertex",
   "metadata": {},
   "source": [
    "## Part 3: Apply open-source model\n",
    "\n",
    "We now download an open-source, pre-trained neural network to \"paint\" our image in the style above. The model is available on the TensorFlow Hub [here](https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model\n",
    "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-multiple",
   "metadata": {},
   "source": [
    "**Q 1:** Apply the style to your image.\n",
    "\n",
    "Hint: Use the `hub_model()` with the `content_image` and `style_image` as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = load_img('myImage.jpg')\n",
    "stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-orientation",
   "metadata": {},
   "source": [
    "**Q 2:** Plot the stylized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_to_image(stylized_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-remains",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EPFL",
   "language": "python",
   "name": "epfl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
